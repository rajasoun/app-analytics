{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Theme Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# List Jupyter Theme\n",
    "!jt -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# toggle toolbar ON and notebook name ON\n",
    "!jt -t grade3 -T -N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages & Track Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the versions of key python librarise\n",
    "# Python\n",
    "import sys\n",
    "import platform\n",
    "print('python: %s' % platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkgs = [\n",
    "    'numpy', 'matplotlib', 'pandas', 'statsmodels', 'sklearn', 'fbprophet',\n",
    "    'numba'\n",
    "]\n",
    "for pkg in pkgs:\n",
    "    try:\n",
    "        globals()['est_module'] = __import__(pkg)\n",
    "        print(pkg, ': %s' % est_module.__version__)\n",
    "    except ModuleNotFoundError:\n",
    "        print(pkg, 'Not Found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "workspace_dir = os.path.realpath('..')\n",
    "print('Workspace Dir ->',workspace_dir )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fbprophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "from numba import jit\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_col(df, col):\n",
    "    group = df.groupby(df[str(col)])\n",
    "    group_by = pd.DataFrame(group.size().reset_index(name=\"Count\"))\n",
    "    return group_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_columns(df, cols):\n",
    "    df = df.drop(list(cols), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cols_type(df):\n",
    "    # Print Column Type\n",
    "    for col in df:\n",
    "        print(str(col), '->', type(df[col][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coerce_columns_to_numeric(df, column_list):\n",
    "    df[column_list] = df[column_list].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil\n",
    "# Convert date from string to date times\n",
    "def coerce_columns_to_date(df, col):\n",
    "    df[str(col)] = df[str(col)].apply(dateutil.parser.parse, dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create a DataFrame in the format required by Prophet\n",
    "def create_df_for_prophet(ts):\n",
    "    ts.columns = [\"ds\", \"y\"]\n",
    "    ts = ts.dropna()\n",
    "    ts.reset_index(drop=True, inplace=True)\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "dir_name = workspace_dir + '/data/output/'\n",
    "\n",
    "\n",
    "def remove_outliers_by_col(df, col):\n",
    "    file = dir_name + 'outliers_' + str(col).lower() + '.csv'\n",
    "    z = np.abs(stats.zscore(df[str(col)]))\n",
    "    threshold = 3\n",
    "    df[(z > 3)].to_csv(file, index=False)\n",
    "    print('Removed Outliers Stores In ->', file)\n",
    "    return df[(z < 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def visualize_outliers_by_col(df, col):\n",
    "    sns.boxplot(x=df[str(col)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove any negative forecasted values.\n",
    "def remove_negtives(ts):\n",
    "    ts['yhat'] = ts['yhat'].clip_lower(0)\n",
    "    ts['yhat_lower'] = ts['yhat_lower'].clip_lower(0)\n",
    "    ts['yhat_upper'] = ts['yhat_upper'].clip_lower(0)\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def mse(y_actual, y_pred):\n",
    "    # compute the mean square error\n",
    "    mse = ((y_actual - y_pred)**2).mean()\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symmetric Mean Absolute Percent Error (SMAPE)\n",
    "#function to calculate in sample SMAPE scores\n",
    "def smape_fast(y_true, y_pred):\n",
    "    out = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        if (y_true[i] != None and np.isnan(y_true[i]) == False):\n",
    "            a = y_true[i]\n",
    "            b = y_pred[i]\n",
    "            c = a + b\n",
    "            if c == 0:\n",
    "                continue\n",
    "            out += math.fabs(a - b) / c\n",
    "    out *= (200.0 / y_true.shape[0])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check - Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required data\n",
    "from subprocess import check_output\n",
    "input_dir = workspace_dir + \"/data/input/\"\n",
    "print(check_output([\"ls\", input_dir ]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict - From Google Analytics Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Clean Up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date_past_data = '2018-08-28' #str(clean_ga_data.ds.max().date())\n",
    "data_file = workspace_dir + \"/data/input/est_daily_access.csv\"\n",
    "ga_data = pd.read_csv(data_file)\n",
    "m = ga_data.shape[0]\n",
    "n = ga_data.shape[1]\n",
    "\n",
    "print('        Data Set Details')\n",
    "print('+++++++++++++++++++++++++++++++')\n",
    "print('# Of Observations', str(m))\n",
    "print('# Of Features', str(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "visualize_outliers_by_col(ga_data, 'Users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_data = remove_outliers_by_col(ga_data, 'Users')\n",
    "m = ga_data.shape[0]\n",
    "print(' Data Set without Outliers')\n",
    "print('+++++++++++++++++++++++++++++++')\n",
    "print('# Of Observations', str(m))\n",
    "ga_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ga_data = create_df_for_prophet(ga_data)\n",
    "coerce_df_columns_to_numeric(clean_ga_data, ['y'])\n",
    "coerce_columns_to_date(clean_ga_data,'ds')\n",
    "print_cols_type(clean_ga_data)\n",
    "clean_ga_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ga_data.set_index('ds').plot(style=['+'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Users')\n",
    "plt.title('User Access By Date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log transform data\n",
    "ga_data['y'] = np.log(ga_data['y'])\n",
    "ga_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_data.set_index('ds').plot(style=['+'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Users')\n",
    "plt.title('Log Of User Access By Date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_csv = workspace_dir + \"/data/input/us_holidays.csv\"\n",
    "us_public_holidays = pd.read_csv(holidays_csv)\n",
    "mdl = Prophet(\n",
    "    interval_width=0.95,\n",
    "    daily_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    yearly_seasonality=True,\n",
    "    holidays=us_public_holidays)\n",
    "mdl.fit(ga_data)\n",
    "\n",
    "ga_future = mdl.make_future_dataframe(\n",
    "    periods=31 + 28, freq='D', include_history=True)\n",
    "ga_forecast = mdl.predict(ga_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(ga_forecast[['yhat', 'yhat_lower', 'yhat_upper']].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_forecast = remove_negtives(ga_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.plot(ga_forecast)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot time series components\n",
    "mdl.plot_components(ga_forecast)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_forecast['yhat'] = np.exp(ga_forecast[['yhat']])\n",
    "ga_forecast['yhat_lower'] = np.exp(ga_forecast[['yhat_lower']])\n",
    "ga_forecast['yhat_upper'] = np.exp(ga_forecast[['yhat_upper']])\n",
    "\n",
    "ga_forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling_csv = workspace_dir + \"/data/output/prediction_based_ga_modelling.csv\"\n",
    "ga_forecast.to_csv(modelling_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retransform using e\n",
    "y_hat = ga_forecast['yhat'][:]\n",
    "y_true = clean_ga_data['y']\n",
    "mse = mse(y_hat, y_true)\n",
    "print('Prediction quality: {:.2f} MSE ({:.2f} RMSE)'.format(mse, math.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = ga_forecast['yhat'][:]\n",
    "y_actual = clean_ga_data['y']\n",
    "smape = smape_fast(y_actual.values, y_prediction.values)\n",
    "print('Prediction quality: SMAPE :  {:.2f}  '.format(smape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = ga_forecast[['ds','yhat', 'yhat_lower', 'yhat_upper']]\n",
    "column_headers = [\n",
    "    'Date', 'PredictedUser', 'Lower(PredictedUser)', 'Upper(PredictedUser)'\n",
    "]\n",
    "prediction.columns = column_headers\n",
    "forecast_csv = workspace_dir + '/data/output/forecast_for_future.csv'\n",
    "prediction_future = prediction[prediction.Date > max_date_past_data]\n",
    "prediction_future.to_csv(forecast_csv, index=False)\n",
    "prediction_future.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ga_forecast[['ds']]\n",
    "actual = clean_ga_data['y']\n",
    "forecast = ga_forecast[['yhat', 'yhat_lower', 'yhat_upper']]\n",
    "frames = [ds, actual, forecast]\n",
    "column_headers = [\n",
    "    'Date', 'ActualUser', 'PredictedUser', 'Lower(PredictedUser)',\n",
    "    'Upper(PredictedUser)'\n",
    "]\n",
    "result = pd.concat(frames, axis=1, join='inner')\n",
    "result.columns = column_headers\n",
    "forecast_csv = workspace_dir + '/data/output/forecast_for_past.csv'\n",
    "result.to_csv(forecast_csv, index=False)\n",
    "result.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jupyter nbconvert --to script *.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
